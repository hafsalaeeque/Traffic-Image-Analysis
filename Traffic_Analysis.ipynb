{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4kFU7X0SUe14"
   },
   "source": [
    "### Transfer learning \n",
    "Training a neural network on traffic images to perform binary classification as:<br>\n",
    "1) **medium** congested, classified as label **1**.<br>\n",
    "2) **low** congested, classified as label **0**.<br>\n",
    "\n",
    "Here we are using [Keras](https://github.com/keras-team/keras) with [TensorFlow](https://www.tensorflow.org/) backend to demostrate transfer learning on the [traffic images API](https://api.data.gov.sg/v1/transport/traffic-images) to classify images.\n",
    "Training is first done on 9 images each from each class, then we 'freeze' the *feature layers* and rebuild the model to classify the remaining images.\n",
    "\n",
    "After 87 images were scrapped each time from the [API](https://api.data.gov.sg/v1/transport/traffic-images) on 2 different times of the day - assuming one was during **peak time** and other was during **off-peak**, they had to be manually labelled.<br>\n",
    "\n",
    "Images have been split to train and test (validation) set in the data folder. <br>\n",
    "\n",
    "#### Import packages\n",
    "Source: https://github.com/keras-team/keras/blob/master/examples/mnist_transfer_cnn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tFTm4-88Ue16"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hafsa\\AppData\\Local\\conda\\conda\\envs\\py35\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#from env py35\n",
    "import datetime\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZlIxHltGUe19"
   },
   "source": [
    "We will be using this later to record how long it takes to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 677,
     "status": "ok",
     "timestamp": 1541076959307,
     "user": {
      "displayName": "Hafsa Laeeque",
      "photoUrl": "",
      "userId": "10133705792695964005"
     },
     "user_tz": -480
    },
    "id": "MBFMgCTTUe19",
    "outputId": "2ee38397-dbca-4af1-facb-1de829d6df51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-21 02:02:40.948787\n"
     ]
    }
   ],
   "source": [
    "now = datetime.datetime.now\n",
    "print (now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pzlD9s3UUe2A"
   },
   "source": [
    "#### Instantiation of hyperparameters\n",
    "\n",
    "Here we instantiate the values of hyperparameters that we will be using later. We will stick to the parameters similar to the deep neural network except for the `epochs` which is reduced, as CNN are more computationally expensive.\n",
    "\n",
    "Some terms to define for my [reference](https://towardsdatascience.com/epoch-vs-iterations-vs-batch-size-4dfb9c7ce9c9):<br>\n",
    "1) `batch_size`: total # of training examples present in the dataset<br>\n",
    "2) `number of batches`: # of sets/parts a dataset is divided.<br>\n",
    "3) `iterations`: # of batches needed to complete one epoch. AKA number of batches.<br>\n",
    "4) `epoch`: when an entire dataset is passed once, forward and backward through the neural network.\n",
    "\n",
    "We have 18 images in the training data. <br>\n",
    "Batch size of 3 images are to be passed in 6 iterations/number of batches for one epoch.<br>\n",
    "OR <br>\n",
    "Batch size of 6 images are to be passed in 3 iterations/number of batches for one epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BVgydGzsUe2B"
   },
   "outputs": [],
   "source": [
    "# I will go with the first choice for the trial\n",
    "batch_size = 3\n",
    "num_classes = 6\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labelling image data\n",
    "As the scrapped data is not labelled, I decided which images to be considered as medium congestion and low congestion. The test data has a 50-50 balance of the medium vs low congestion.\n",
    "Now, I would need to label the images as such that the image is labelled as class `0` or `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Height: 458.6666666666667\n",
      "Max Height: 480\n",
      "Min Height: 288\n",
      "\n",
      "\n",
      "Average Width: 611.5555555555555\n",
      "Max Width: 640\n",
      "Min Width: 384\n"
     ]
    }
   ],
   "source": [
    "DIR = './data/train'\n",
    "\n",
    "# First, I need to figure how I should format the height x width image dimensions\n",
    "# to input to a keras model\n",
    "def get_size_statistics():\n",
    "    heights = []\n",
    "    widths = []\n",
    "    img_count = 0\n",
    "    for img in os.listdir(DIR):\n",
    "        path = os.path.join(DIR, img)\n",
    "        if \"DS_Store\" not in path:\n",
    "            data = np.array(Image.open(path))\n",
    "            heights.append(data.shape[0])\n",
    "            widths.append(data.shape[1])\n",
    "            img_count += 1\n",
    "    avg_height = sum(heights) / len(heights)\n",
    "    avg_width = sum(widths) / len(widths)\n",
    "    print(\"Average Height: \" + str(avg_height))\n",
    "    print(\"Max Height: \" + str(max(heights)))\n",
    "    print(\"Min Height: \" + str(min(heights)))\n",
    "    print('\\n')\n",
    "    print(\"Average Width: \" + str(avg_width))\n",
    "    print(\"Max Width: \" + str(max(widths)))\n",
    "    print(\"Min Width: \" + str(min(widths)))\n",
    "\n",
    "get_size_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nNQLPStEUe26"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iFEMGdNRUe29"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DAGa_zLnUe2-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Week 3 - Transfer learning on the MNIST dataset.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
